# Compétence 1 - Réaliser un développement d’application

Au cours de ma deuxième année d'alternance au sein de l'entreprise Amphenol FCI Besançon j'ai été amméné à continuer le
développement de l'application que j'ai pu réaliser en première année
pour ainsi rajouter des fonctionnalités. L'application est une application de gestion de feuille process, c'est à dire
que l'on peut y réaliser des relevés de caractéristiques sur des produits en production.
L'application est développée en VueJS côté frontend et NodeJS côté backend avec une base de données PostgreSQL.

L'application, pour rappel permet de réaliser des relevés de caractéristique sur des produits en production afin d'être
conforme aux spécifications.
Un opérateur va donc, pour un produit, sur une ligne de production, relever toutes les caractéristiques étapes par
étapes et compléter le relevé.

Une fois le relevé réalisé celui ci est enregistré dans la base de données permettant ainsi d'agir comme un historique
des relevés.

Au sein de ses historiques il y a donc toutes les valeurs relevé par l'opérateur à un moment T, des valeurs qui peuvent
sortir des spécifications notamment.

Avec plusieurs relevés effectués quotidiennement (minimum 3 par jour), l'entreprise totalise actuellement plus de 1500
relevés stockés en base de données. Ces données servent à la fois à l'historisation et au suivi de la qualité des
produits.

## Problématique identifiée

Le principal problème réside dans l'impossibilité de visualiser rapidement et efficacement l'évolution des
caractéristiques mesurées. Pour analyser l'évolution d'une caractéristique, il est nécessaire de consulter manuellement
chaque relevé individuellement, ce qui s'avère chronophage et peu pratique.

Cette limitation empêche de :

- Vérifier en temps réel si la production respecte les spécifications
- Détecter les dérives de caractéristiques avant qu'elles ne deviennent problématiques
- Prendre des mesures correctives préventives

## Impact métier

Cette problématique a récemment causé un incident qualité lors d'un audit client. Plusieurs relevés présentaient des
valeurs hors spécification qui n'ont pas pu être détectées à temps, faute d'outil de visualisation approprié. Cette
situation rappelle les difficultés rencontrées avant la numérisation des relevés.

# Solution

Pour répondre à cette problématique, j'ai conçu et développé un dashboard de suivi des caractéristiques permettant de
visualiser l'évolution des données de production de manière graphique et intuitive.

<figure>
  <img alt="Dashboard" height="900" src="/portfolio/images_portfolio/dashboard.png" width="100%"/>
  <figcaption style="font-size: 1.2em;">
    Tableau de bord de suivi des relevés 
  </figcaption>
</figure>

## Architecture de sécurité mise en place

L'accès au dashboard est sécurisé par un système d'authentification et d'autorisation basé sur les rôles utilisateurs :

### Gestion des accès par rôles

- **Administrateur** : Accès complet aux fonctionnalités
- **Technicien Process (TP)** : Consultation et gestion des feuilles process
- **Ingénieurs/Service Qualité** : Consultation des données statistiques

Les opérateurs de production n'ont volontairement pas accès à cette interface, leur rôle se limitant à la saisie des
relevés.

### Implémentation technique de la sécurité

J'ai mis en place une architecture de sécurité comprenant :

- **Hachage des mots de passe** avec bcrypt pour la protection des données d'authentification
- **Authentification stateless** via JSON Web Token (JWT)
- **Vérification des autorisations** à chaque requête pour contrôler l'accès aux fonctionnalités selon le rôle
  utilisateur
- **Stockage sécurisé** des credentials en base de données

Cette approche garantit la confidentialité des données de production tout en permettant aux équipes autorisées d'accéder
aux outils d'analyse nécessaires.

----------------

## Interface utilisateur du dashboard

Une fois authentifié, l'utilisateur accède au dashboard composé de plusieurs sections :

### Tableau de bord statistiques

Une barre d'indicateurs présente les métriques clés de production en temps réel :

- **Taux de non-conformité** : Pourcentage de relevés présentant des caractéristiques hors spécifications
- **Volume de production** : Nombre de relevés effectués (mensuel, hebdomadaire, par ligne)
- **Indicateurs de performance** par ligne de production

*Exemple* : Une température avec des bornes de 60° à 80° déclenchera un statut "Hors Spécification" (HS) si la valeur
relevée atteint 90°. Un taux HS faible indique une production conforme.

### Implémentation technique

#### Chargement des données

J'ai utilisé le **lifecycle hook `onMounted`** de Vue.js pour déclencher la récupération des données dès
l'initialisation du composant :

- **Frontend** : Requêtes API via Axios
- **Backend** : Requêtes SQL optimisées sur PostgreSQL
- **Traitement** : Calcul automatique des ratios de non-conformité

#### Système de classification automatique

Chaque relevé est automatiquement évalué lors de sa sauvegarde :

**Critères d'évaluation :**

- Valeurs hors spécifications techniques
- Données manquantes obligatoires
- Éléments de contrôle non validés

**Résultat :** Attribution d'un booléen `is_hors_spec` permettant le calcul en temps réel des indicateurs de qualité.

Cette approche garantit une traçabilité complète et des statistiques fiables pour le pilotage de la production.

---------------------

### Interface de sélection des données

Le dashboard propose un système de filtrage avancé composé de quatre sélecteurs principaux :

- **Ligne de production** : Filtrage par ligne active uniquement
- **Référence produit** : Nom du produit à analyser
- **Caractéristique** : Type de mesure (température, intensité, tension, pH, débit, longueur de cellule)
- **Étape** : Phase spécifique du processus de production

#### Gestion intelligente des données disponibles

J'ai implémenté un système de filtrage dynamique pour optimiser l'expérience utilisateur. Les étapes proposées sont
automatiquement filtrées selon la disponibilité des caractéristiques sélectionnées.

**Logique métier :** Chaque caractéristique n'est pas mesurée à toutes les étapes. Par exemple, une température peut
être relevée aux étapes 1 et 3 mais pas à l'étape 2. Le système vérifie donc la présence de données avant de proposer
les options. Par exemple il ne va pas y avoir de température à relever pour l'étape 8 qui concerne la caméra.

#### Architecture de base de données

La complexité des relations entre étapes et caractéristiques est gérée par un modèle relationnel adapté :

**Structure des données :**

- Chaque étape possède un numéro, une description et un état
- Les caractéristiques sont liées aux étapes via des tables de jonction (`multi_temp`, `multi_ampere`, etc.)
- Chaque caractéristique définit des coefficients minimal et maximal

#### Implémentation technique du filtrage

```js
exports.getEtapeByMulti = async (refPlating, multiTable) => {
    let multiCondition = '';
    let multiWhere = '';

    // Construction dynamique des jointures selon la caractéristique
    if (multiTable === 'temperature') {
        multiCondition = 'JOIN public.multi_temp mt on me.id_multi_etape = mt.fk_multi_etape_temp';
        multiWhere = 'mt.fk_chauffage is not null';
    } else if (multiTable === 'amperage') {
        multiCondition = 'JOIN public.multi_ampere ma on me.id_multi_etape = ma.fk_multi_etape_ampere';
        multiWhere = 'ma.fk_ampere is not null';
    }
    // ... autres caractéristiques

    const query = `
        SELECT nom_etape
        FROM etape
        JOIN public.multi_etape me ON etape.id_etape = me.fk_etape
        ${multiCondition}
        JOIN public.ligne ON ligne.id_ligne = me.fk_ligne_etape
        JOIN public.produit ON produit.fk_ligne = ligne.id_ligne
        WHERE produit.ref_plating LIKE :refPlating || '%'
          AND ${multiWhere}
        GROUP BY nom_etape, me.num_ordre
        ORDER BY me.num_ordre;
    `;

    return await db.sequelize.query(query, {
        replacements: {refPlating: refPlating},
        type: db.sequelize.QueryTypes.SELECT
    });
};
```

Cette approche permet d'éviter les sélections inutiles et garantit que l'utilisateur ne se retrouve pas avec des
graphiques vides.

---------------

Je vous ai parlé des quatres sélecteurs mais il en manque un, c'est plutôt deux sélecteur en un.

L'utilisateur peut sélectionner un produit, du moins c'est un champ input où il peut renseigner le nom du produit et
cela retournera en temp réel les produits correspondant au produit écrit. Cela fonctionne avec la propriété LIKE en SQL
où je récupère via v-model et donc une liaison bi directionnelle le nom du produit.

Ainsi si par exemple j'écrit dans le champ input << F_77310-11 >> cela va me retourner tout les produits commençant
par << F_77310-11 >>. Alors la recherche est en temps réel, ce qui pourrait causer d'éventuel problème si l'application
était accessible à un grand nombre d'utilisateur et en simultané du fait qu'à chaque input il y a une requête effectué
au serveur. Cependant il n'y a que une dizaine de personnes ayant accès au Dashboard et en simultané il y a au mieux
deux personnes.

Si c'était réellement primordial d'optimiser cela alors, je pourrais implémenter une solution à savoir le  <<
Debouncing >> qui est d'ajouter un temps d'arrêt avant que la requêtes ne s'éxécute, un temps de chargement finalement
pour brider les requêtes envoyer et in fine éviter la surchage.

Une fois le produit entré, l'utilisateur peut si il le souhaite sélectionner précisèment ces produits. Par défaut si
l'utilisateur clique sur << Générer les statistiques >> cela prendra tout les produits commençant par, ici <<
F_77310-11 >> dans la génération du graphique, si il sélectionne ces produits alors, je stock ces derniers dans un
tableau, en vérifiant si il n'existe pas déjà, si la taille du tableau est supérieure à 0 alors je prends les élements
de ce dernier pour la génération du graphique.

L'utilisateur peut donc sélectionner un produit mais aussi le retirer, si il le souhaite, en cliquant dessus pour le <<
pop >> du tableau.

----------

Une fois le ou les produits sélectionné(e), je réalise alors deux requêtes voir trace 3

```js
exports.getCaractOnEtape = async (params) => {
    const {mode, caracteristic, caracteristicOpti, nomLigne, pnPlating, etape} = params;

    let pnPlatingCondition = '';
    if (mode === '0') {
        const pnArray = pnPlating.split(',').map(pn => `'${pn}'`);
        pnPlatingCondition = `nom_pn_plating IN (${pnArray.join(',')})`;
    } else if (mode === '1') {
        pnPlatingCondition = `nom_pn_plating LIKE '${pnPlating}' || '%'`;
    }

    const query = `
        SELECT elem -> :caracteristic ->> :caracteristicOpti AS caracteristic_opti,
               TO_CHAR(date_releve, 'DD/MM/YYYY HH24:MI:SS') AS date_releve,
               nom_pn_plating,
               initiale_user,
               initiale_userat,
               input_vitesse ->> 'inputVitesse'              AS input_vitesse
        FROM historique,
             LATERAL jsonb_array_elements(input_releve) AS elem
        WHERE nom_ligne = :nomLigne
          AND ${pnPlatingCondition}
          AND elem ->> 'etape' = :etape;
    `;

    return await db.sequelize.query(query, {
        replacements: {
            mode,
            caracteristic,
            caracteristicOpti,
            nomLigne,
            pnPlating,
            etape
        },
        type: db.sequelize.QueryTypes.SELECT
    });
};
```

La première requête `getCaractOnEtape` va me récupérer les valeurs mesurées de la caractéristique choisie avec ces
paramètres :

- caracteristic,
- caracteristicOpti,
- nomLigne,
- pnPlating,
- etape

Ce sont simplement les paramètres mis plus haut, mais il y en manque un, le mode.

Le mode est simplement un outil pour me permettre de sélectionner le type de données envoyer pour le produit
sélectionné.

Si le mode est à 0 dans l'envoi de la requête l'on a à faire au tableau des valeurs sélectionné, sinon l'on prend le
LIKE pour la requête. J'ai mis en place ce système, de base, pour une autre fonctionnalité concernant la mise à jour des
feuille process, où j'avais du code qui se répété, j'ai donc réfléchi à une solution me permettant de segmenter le type
de la requête, à savoir si je m'occupe d'une grande sélection `LIKE`, d'une sélection précise `=` ou d'une sélection
multiple `IN` à partir de là avec sequelize je peux déterminer le type de requête.

Une fois la sélection du mode faites, il me faut réaliser la requête, alors, c'est un peu particulier.
Un relevé fait par l'opérateur est stocké en base.

Un relevé est composé de plusieurs éléments :

- input_toggle (Concerne les cases à cocher pour déterminer si un état d'une étape est conforme)
- initiale_user (Les initiales de l'opérateur deux première lettre du nom et du prénom exemple LALU pour Lauret Lucas)
- initiale_userat (Initiale de l'assistant technique qui aide pendant le relevé et le réglage de la ligne de production)
- initiale_usertp (Initiale du technicien process qui est null par défaut, se rempli si il vient rajouter un commentaire
  depuis son interface afin de compléter un relévé ou autre)
- commentaire_tp
- date_releve
- nom_pn_plating (nom du produit)
- commentaire (commentaire de l'opérateur sur le relevé pour justifier des valeurs HS)
- nom_ligne (Ligne de production)
- pn_brut (nom brut du produit)
- nom_famille (nom de la famille de produit)
- input_vitesse (objet json regroupant la vitesse relevé et ses coef)
- input_pression
- is_hors_spec (booléen)
- input_releve (Contient la totalité du relevé)

Les valeurs renseigné sont mise sous forme d'un objet JSON comme suit

```json
{
  "nom_etat": "2 FACES",
  "nom_ligne": "F",
  "pn_plating": "77391-122LF",
  "description": "Regulation moteur",
  "etape": "1",
  "station": "Degraissage1",
  "ph": {
    "phMax": 0,
    "phMin": 0,
    "phOpti": null
  },
  "debit": {
    "debitMax": 0,
    "debitMin": 0,
    "debitOpti": null
  },
  "voltage": {
    "voltageMax": 0,
    "voltageMin": 0,
    "voltageOpti": null
  },
  "amperage": {
    "amperageMax": 0,
    "amperageMin": 0,
    "amperageOpti": null
  },
  "temperature": {
    "temperatureMax": 0,
    "temperatureMin": 0,
    "temperatureOpti": null
  },
  "longueurCellule": {
    "longueurCelluleMax": 0,
    "longueurCelluleMin": 0,
    "longueurCelluleOpti": null
  }
}
...
  ```

Cet objet fois le nombre d'étape. Ce qui donne en moyenne une cinquantaine d'objet comme celui ci.

Cet objet est stocké directement dans la base, j'ai décidé de stocker directement l'objet JSON, simplement car cela
aurait été plus complexe d'un point de vue relationnel, au vu de la nature même d'une feuille process, il aurait fallu
créer soit plusieurs colonnes, soit le stocker en texte etc.
Mais j'ai décidé que ces `input_releve` soit stocké en JSON, en JSONB pour être plus précis.
Le type JSON va stocker en texte, tandis que le JSONB va stocker en format binaire la structure, c'est plus efficace
pour les requêtes.

Les requêtes postgreSQL sont différentes, il faut utiliser des flèches pour accéder aux objets et sous objets qui nous
intéresse, ici ce sont les valeurs ayant comme clé "Opti" qui concerne les valeurs relevés, par défaut elles sont à
null, c'est à dire qu'il n'y a pas par exemple de température à cette étape d'où les coefficients à 0.
Visuellement pour l'opérateur ça représente une cellule noire.

Je vais donc chercher ces valeurs "Opti" :
`SELECT elem -> :caracteristic ->> :caracteristicOpti AS caracteristic_opti`
ainsi que la vitesse :  `input_vitesse ->> 'inputVitesse'              AS input_vitesse`

Cela me retourne un tableau :

```json
{
  "caracteristic_opti": "30",
  "date_releve": "07/03/2025 15:05:30",
  "nom_pn_plating": "77310-159LF",
  "initiale_user": "LAMA",
  "initiale_userat": "",
  "input_vitesse": "6.7"
}
```

que je peux donc exploiter pour mon graphique en récupérant donc la date et la valeur pour constituer mes axes.

Afin d'établir mes limites je réalise aussi une requête qui va me récupérer les moyennes hautes et basse

```js
exports.getAverageOnValue = async (params) => {
    const {mode, caracteristic, caracteristicMin, caracteristicMax, nomLigne, pnPlating, etape} = params;

    let pnPlatingCondition = '';
    if (mode === '0') {
        const pnArray = pnPlating.split(',').map(pn => `'${pn}'`);
        pnPlatingCondition = `nom_pn_plating IN (${pnArray.join(',')})`;
    } else if (mode === '1') {
        pnPlatingCondition = `nom_pn_plating LIKE '${pnPlating}' || '%'`;
    }

    const query = `
        SELECT ROUND(AVG((elem -> :caracteristic ->> :caracteristicMin)::numeric), 2) AS average_caracteristic_min,
               ROUND(AVG((elem -> :caracteristic ->> :caracteristicMax)::numeric), 2) AS average_caracteristic_max
        FROM historique,
             LATERAL jsonb_array_elements(input_releve) AS elem
        WHERE nom_ligne = :nomLigne
          AND ${pnPlatingCondition}
          AND elem ->> 'etape' = :etape;
    `;

    return await db.sequelize.query(query, {
        replacements: {
            mode,
            caracteristic,
            caracteristicMin,
            caracteristicMax,
            nomLigne,
            pnPlating,
            etape
        },
        type: db.sequelize.QueryTypes.SELECT
    });
};
```

Même principe que précèdement cepandant je fais la moyenne, qui va me permmtre d'appliquer des limites.

In fine nous avons un joli graphique, (enfin tout est relatif)  avec ApexChart sur l'évolution des caractéristiques
sélectionnées pour un ou plusieurs produits.

Ce graphique ne sert pas à faire beau, il est très utile afin de voir si il n'y a pas d'anomalies de production sur
l'ensemble des relevés, et si anomalie il y a, alors aviser la dites caractéristique pour par exemple élargir la plage
minimale et maximale ou bien la diminuer.

J'ai pu mettre en oeuvre le développement au sein d'une application existante, donc l'ajout de fonctionnalité,
Développer la sélection et l'envoie de données hétérogène via une api afin de l'exploiter de manière statistique.